{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strands and Agent-to-Agent (A2A) Protocol\n",
    "\n",
    "Strands Agents supports the [Agent-to-Agent (A2A)](https://strandsagents.com/latest/documentation/docs/user-guide/concepts/multi-agent/agent-to-agent/), an open standard that defines how AI agents can discover, communicate, and collaborate with each other. Enabling seamless communication between AI agents across different platforms and implementations.\n",
    "\n",
    "### What is Agent-to-Agent (A2A) Communication?\n",
    "\n",
    "The Agent-to-Agent protocol is an open standard that defines how AI agents can discover, communicate, and collaborate with each other.\n",
    "\n",
    "A2A protocol support enables several powerful use cases:\n",
    "\n",
    "- Multi-Agent Workflows: Chain multiple specialized agents together\n",
    "- Agent Marketplaces: Discover and use agents from different providers\n",
    "- Cross-Platform Integration: Connect Strands agents with other A2A-compatible systems\n",
    "- Distributed AI Systems: Build scalable, distributed agent architectures\n",
    "\n",
    "### MCP vs A2A\n",
    "\n",
    "It's important to understand how A2A relates to MCP, or Model Context Protocol. These are complementary standards.\n",
    "\n",
    "- MCP connects agents to tools, APIs, and resources with structured inputs/outputs. Think of it as how agents access their capabilities.\n",
    "\n",
    "- A2A facilitates dynamic communication between different agents as peers. It's how agents collaborate, delegate, and manage shared tasks.\n",
    "\n",
    "They're complementary - MCP gives agents their tools, A2A enables collaboration.\n",
    "click\n",
    "\n",
    "### A2A Architecture \n",
    "\n",
    "- **Primary Agent**: Initiates communication and delegates tasks (the \"manager\")\n",
    "- **Secondary Agent(s)**: Receive tasks and provide responses (the \"specialists\")\n",
    "- **A2A Tool**: Handles protocol details for seamless communication between the agents\n",
    "- **Message Protocol**: Defines message format and structure\n",
    "\n",
    "![a2a](image/a2a.png)\n",
    "\n",
    "### Learn more about the A2A protocol:\n",
    "\n",
    "- [A2A GitHub Organization](https://github.com/a2aproject/A2A)\n",
    "- [A2A Python SDK](https://github.com/a2aproject/a2a-python)\n",
    "- [A2A Documentation](https://a2aproject.github.io/A2A/latest/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… Lests bild an A2A aplication\n",
    "\n",
    "In this section, we will do a walkthrough of selected code blocks, that have been used to build [strands-a2a-inter-agent](strands-a2a-inter-agent/), based on the [sample-agentic-ai-demos repositorie](https://github.com/aws-samples/sample-agentic-ai-demos/tree/main/modules/strands-a2a-inter-agent) to create a A2A agent.\n",
    "\n",
    "In our example, we'll explore a three-tier architecture where:\n",
    "- An [HR Agent](strands-a2a-inter-agent/hr-agent.py) communicates with an Employee Agent\n",
    "- The [Employee Agent](strands-a2a-inter-agent/employee-agent.py) communicates with an MCP Server\n",
    "- The [MCP Server](strands-a2a-inter-agent/server.py) provides access to employee data\n",
    "\n",
    "![a2a_architecture](image/a2a_example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Employee Data\n",
    "\n",
    "First, we have a simple module that generates random employee data with skills:\n",
    "\n",
    "```python\n",
    "import random\n",
    "\n",
    "FIRST_NAMES = [\"James\", \"Mary\", \"John\", \"Patricia\", \"Robert\", \"Jennifer\", \"Michael\", \"Linda\", \"William\", \"Elizabeth\"]\n",
    "LAST_NAMES = [\"Smith\", \"Johnson\", \"Williams\", \"Brown\", \"Jones\", \"Garcia\", \"Miller\", \"Davis\", \"Rodriguez\", \"Martinez\"]\n",
    "\n",
    "SKILLS = {\n",
    "    \"Kotlin\", \"Java\", \"Python\", \"JavaScript\", \"TypeScript\",\n",
    "    \"React\", \"Angular\", \"Spring Boot\", \"AWS\", \"Docker\",\n",
    "    \"Kubernetes\", \"SQL\", \"MongoDB\", \"Git\", \"CI/CD\",\n",
    "    \"Machine Learning\", \"DevOps\", \"Node.js\", \"REST API\", \"GraphQL\"\n",
    "}\n",
    "\n",
    "EMPLOYEES = list({emp[\"name\"]: emp for emp in [\n",
    "    {\n",
    "        \"name\": f\"{random.choice(FIRST_NAMES)} {random.choice(LAST_NAMES)}\",\n",
    "        \"skills\": random.sample(list(SKILLS), random.randint(2, 5))\n",
    "    }\n",
    "    for i in range(100)\n",
    "]}.values())\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. MCP Server\n",
    "\n",
    "Next, we have an MCP server that exposes tools to access the employee data:\n",
    "\n",
    "\n",
    "```python\n",
    "from mcp.server.fastmcp import FastMCP\n",
    "\n",
    "from employee_data import SKILLS, EMPLOYEES\n",
    "\n",
    "mcp = FastMCP(\"employee-server\", stateless_http=True, host=\"0.0.0.0\", port=8002)\n",
    "\n",
    "@mcp.tool()\n",
    "def get_skills() -> set[str]:\n",
    "    \"\"\"all of the skills that employees may have - use this list to figure out related skills\"\"\"\n",
    "    print(\"get_skills\")\n",
    "    return SKILLS\n",
    "\n",
    "@mcp.tool()\n",
    "def get_employees_with_skill(skill: str) -> list[dict]:\n",
    "    \"\"\"employees that have a specified skill - output includes fullname (First Last) and their skills\"\"\"\n",
    "    print(f\"get_employees_with_skill({skill})\")\n",
    "    skill_lower = skill.lower()\n",
    "    employees_with_skill = [employee for employee in EMPLOYEES if any(s.lower() == skill_lower for s in employee[\"skills\"])]\n",
    "    if not employees_with_skill:\n",
    "        raise ValueError(f\"No employees have the {skill} skill\")\n",
    "    return employees_with_skill\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mcp.run(transport=\"streamable-http\")\n",
    "    \n",
    "```\n",
    "\n",
    "The MCP server exposes two tools:\n",
    "1. `get_skills()`: Returns all possible skills that employees may have\n",
    "2. `get_employees_with_skill(skill)`: Returns employees that have a specific skill\n",
    "\n",
    "These tools are exposed via the Model Context Protocol (MCP) using the FastMCP framework, which provides a standardized way for agents to access these functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Employee Agent\n",
    "\n",
    "The Employee Agent connects to the MCP server and exposes its capabilities through an A2A server:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```python\n",
    "import os\n",
    "from mcp.client.streamable_http import streamablehttp_client\n",
    "from strands import Agent\n",
    "from strands.tools.mcp.mcp_client import MCPClient\n",
    "from strands.multiagent.a2a import A2AServer\n",
    "from urllib.parse import urlparse\n",
    "from strands.models.anthropic import AnthropicModel\n",
    "\n",
    "\n",
    "# Define URLs correctly\n",
    "EMPLOYEE_INFO_URL = \"http://localhost:8002/mcp/\"\n",
    "EMPLOYEE_AGENT_URL = \"http://localhost:8001/\"\n",
    "\n",
    "# Create the MCP client\n",
    "employee_mcp_client = MCPClient(lambda: streamablehttp_client(EMPLOYEE_INFO_URL))\n",
    "\n",
    "model = AnthropicModel(\n",
    "    client_args={\n",
    "        \"api_key\": \"YOUR_API_KEY_HERE\", # Replace with your API key\n",
    "    },\n",
    "    max_tokens=1028,\n",
    "    model_id=\"claude-sonnet-4-20250514\",\n",
    "    params={\n",
    "        \"temperature\": 0.7,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Use the MCP client within a context\n",
    "with employee_mcp_client:\n",
    "    tools = employee_mcp_client.list_tools_sync()\n",
    "    \n",
    "    # Create a Strands agent\n",
    "    employee_agent = Agent(\n",
    "        model=model,\n",
    "        name=\"Employee Agent\",\n",
    "        description=\"Answers questions about employees\",\n",
    "        tools=tools,\n",
    "        system_prompt=\"you must abbreviate employee first names and list all their skills\"\n",
    "    )\n",
    "    \n",
    "    # Create A2A server\n",
    "    a2a_server = A2AServer(\n",
    "        agent=employee_agent, \n",
    "        host=urlparse(EMPLOYEE_AGENT_URL).hostname, \n",
    "        port=int(urlparse(EMPLOYEE_AGENT_URL).port)\n",
    "    )\n",
    "    \n",
    "    # Start the server\n",
    "    if __name__ == \"__main__\":\n",
    "        a2a_server.serve(host=\"0.0.0.0\", port=8001)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Server Configuration Options](https://strandsagents.com/latest/documentation/docs/user-guide/concepts/multi-agent/agent-to-agent/#server-configuration-options)\n",
    "The A2AServer exposes the agent's capabilities to other agents through an HTTP API and accepts several configuration options:\n",
    "\n",
    "- **agent**: The Strands Agent to wrap with A2A compatibility\n",
    "- **host**: Hostname or IP address to bind to (default: \"0.0.0.0\")\n",
    "- **port**: Port to bind to (default: 9000)\n",
    "- **ersion**: Version of the agent (default: \"0.0.1\")\n",
    "- **skills**: Custom list of agent skills (default: auto-generated from tools)\n",
    "- **http_url**: Public HTTP URL where this agent will be accessible (optional, enables path-based mounting)\n",
    "- **serve_at_root**: Forces server to serve at root path regardless of http_url path (default: False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "source": [
    "## 4. HR Agent\n",
    "\n",
    "Finally, the HR Agent provides a user-facing API and communicates with the Employee Agent.\n",
    "\n",
    "- Creates a FastAPI application to handle HTTP requests\n",
    "- Uses the A2AClientToolProvider for discovering and interacting with A2A agents without manually writing client code.\n",
    "- Provides an endpoint for users to ask questions about employees\n",
    "\n",
    "This agent serves as the entry point for user queries and delegates specialized tasks to the Employee Agent when needed.\n",
    "\n",
    "\n",
    "```python\n",
    "import os\n",
    "\n",
    "import uvicorn\n",
    "from strands import Agent\n",
    "from strands.models import BedrockModel\n",
    "from strands_tools.a2a_client import A2AClientToolProvider\n",
    "from fastapi import FastAPI\n",
    "from fastapi.responses import StreamingResponse\n",
    "from pydantic import BaseModel\n",
    "\n",
    "EMPLOYEE_AGENT_URL = \"http://localhost:8001/\"\n",
    "\n",
    "app = FastAPI(title=\"HR Agent API\")\n",
    "\n",
    "class QuestionRequest(BaseModel):\n",
    "    question: str\n",
    "\n",
    "@app.get(\"/health\")\n",
    "def health_check():\n",
    "    return {\"status\": \"healthy\"}\n",
    "\n",
    "model = AnthropicModel(\n",
    "    client_args={\n",
    "        \"api_key\": os.getenv(\"api_key\"),\n",
    "    },\n",
    "    # **model_config\n",
    "    max_tokens=1028,\n",
    "    model_id=\"claude-3-7-sonnet-20250219\",\n",
    "    params={\n",
    "        \"temperature\": 0.3,\n",
    "    }\n",
    ")\n",
    "\n",
    "@app.post(\"/inquire\")\n",
    "async def ask_agent(request: QuestionRequest):\n",
    "    async def generate():\n",
    "        provider = A2AClientToolProvider(known_agent_urls=[EMPLOYEE_AGENT_URL])\n",
    "\n",
    "        agent = Agent(model=bedrock_model, tools=provider.tools)\n",
    "\n",
    "        stream_response = agent.stream_async(request.question)\n",
    "\n",
    "        async for event in stream_response:\n",
    "            if \"data\" in event:\n",
    "                yield event[\"data\"]\n",
    "\n",
    "    return StreamingResponse(\n",
    "        generate(),\n",
    "        media_type=\"text/plain\"\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… Running the Example\n",
    "\n",
    "### Option 1: Run each component in a separate terminal:\n",
    "\n",
    "**1. Set your API key:**\n",
    " ```bash\n",
    "   export api_key='your-anthropic-api-key-here'\n",
    "```\n",
    "\n",
    "**2. Install Required Packages:**\n",
    "\n",
    " ```bash\n",
    "   !pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "**3. Start the MCP Server:**\n",
    "```bash\n",
    "python3 strands-a2a-inter-agent/server.py\n",
    "```\n",
    "\n",
    "**4. Start the Employee Agent:**\n",
    "```bash\n",
    "python employee-agent.py\n",
    "```\n",
    "\n",
    "**5. Start the HR Agent:**\n",
    "```bash\n",
    "python hr-agent.py\n",
    "```\n",
    "\n",
    "**6. Make a request to the HR Agent:**\n",
    "\n",
    "Once all three components are running, you can make requests to the HR Agent:\n",
    "\n",
    "```bash\n",
    "curl -X POST --location \"http://0.0.0.0:8000/inquire\" \\\n",
    "-H \"Content-Type: application/json\" \\\n",
    "-d '{\"question\": \"list employees that have skills related to AI programming\"}'\n",
    "```\n",
    "\n",
    "### Option 2: Runs the MCP Server, Employee Agent, and HR Agent in parallel\n",
    "\n",
    "**1. Set your API key:**\n",
    " ```bash\n",
    "   export api_key='your-anthropic-api-key-here'\n",
    "```\n",
    "\n",
    "**2. Install Required Packages:**\n",
    "\n",
    " ```bash\n",
    "   !pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "**3. Start the system:**\n",
    "  ```bash\n",
    "   python run_a2a_system.py\n",
    "```\n",
    "\n",
    "**4. Make Requests to the HR Agent**\n",
    "\n",
    "Once all three components are running, you can make requests to the HR Agent:\n",
    "\n",
    "```bash\n",
    "curl -X POST --location \"http://0.0.0.0:8000/inquire\" \\\n",
    "-H \"Content-Type: application/json\" \\\n",
    "-d '{\"question\": \"list employees that have skills related to AI programming\"}'\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
